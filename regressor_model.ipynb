{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regressor_model.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN4LKcGerbVOv/3EjLbSiZ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddtheshah/vc_modeling/blob/master/regressor_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uV182SZ1d2Es",
        "colab_type": "text"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lswTEjiPegUo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "d8db23d7-c1ac-4a10-a388-8b75b8f5c2d3"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.sparse\n",
        "!pip install cityhash\n",
        "import cityhash\n",
        "import sklearn.decomposition\n",
        "\n",
        "print(pd.__version__)\n",
        "\n",
        "from copy import deepcopy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cityhash in /usr/local/lib/python3.6/dist-packages (0.2.3.post9)\n",
            "1.0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2WrUtBZenFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "463a29dc-7452-4fb1-b7ca-42117dd478ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJAKI4bLd5ZE",
        "colab_type": "text"
      },
      "source": [
        "# Read/Join Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mez-3_o6t-F-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_folder = '/content/gdrive/My Drive/vc_modeling/feature_extraction'\n",
        "\n",
        "sparse_category_features_array = scipy.sparse.load_npz(feature_folder + \"/category_features/category_features_large.npz\")\n",
        "sparse_region_features_array = scipy.sparse.load_npz(feature_folder + \"/region_features/region_features.npz\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv7LelH2eqbw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "057e6860-37bf-41fd-e309-45efeb69120f"
      },
      "source": [
        "# print(sparse_category_features_array)\n",
        "## Other features here!! Remember to sparsify the dataframes if they're dense!\n",
        "\n",
        "# print(sparse_category_features_array)\n",
        "\n",
        "category_features_array = scipy.sparse.coo_matrix(sparse_category_features_array, dtype=np.uint64)\n",
        "region_features_array = scipy.sparse.coo_matrix(sparse_region_features_array, dtype=np.uint64)\n",
        "\n",
        "print(category_features_array.getnnz())\n",
        "print(region_features_array.getnnz())\n",
        "\n",
        "category_features_df = pd.DataFrame.sparse.from_spmatrix(category_features_array)\n",
        "region_features_df = pd.DataFrame.sparse.from_spmatrix(region_features_array)\n",
        "\n",
        "print(np.shape(category_features_df))\n",
        "print(np.shape(region_features_df))\n",
        "\n",
        "print(\"{}\".format(category_features_df.iloc[0][0]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2355537\n",
            "1681588\n",
            "(963967, 676)\n",
            "(842699, 1032)\n",
            "13685534557686295101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHqwaNc89w2w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "04eaedeb-9b66-4dc4-9faa-9d4efe21a73b"
      },
      "source": [
        "region_uuid = region_features_df.iloc[:, 0]\n",
        "category_uuid = category_features_df.iloc[:, 0]\n",
        "print(region_uuid)\n",
        "\n",
        "print(np.count_nonzero(category_uuid.isin(region_uuid)))\n",
        "check_value = 7551169957279540846\n",
        "# check_value = cityhash.CityHash64('ffffabce-6d4a-b3d1-13c0-4e90cedf5270')\n",
        "print(check_value)\n",
        "print(np.size(region_uuid[region_uuid == check_value]))\n",
        "print(np.size(category_uuid[category_uuid == check_value]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0         13685534557686295101\n",
            "1           764015621929367586\n",
            "2         10846552445983457719\n",
            "3          5087506707876194815\n",
            "4          9094535307341385563\n",
            "                  ...         \n",
            "842694     4626564123199390189\n",
            "842695     2978566027619600648\n",
            "842696     1747954284855665241\n",
            "842697     9744251496066876000\n",
            "842698     7648380604111671063\n",
            "Name: 0, Length: 842699, dtype: Sparse[uint64, 0]\n",
            "808944\n",
            "7551169957279540846\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X7VTKkb_Fd-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "80fb444f-81fd-4a26-c549-f41d84677221"
      },
      "source": [
        "join_base = category_features_df.set_index(0)\n",
        "join1 = region_features_df.set_index(0)\n",
        "full_feature_join = join_base.join(join1, lsuffix='category_features', rsuffix='region_features')\n",
        "full_feature_join = full_feature_join.dropna()\n",
        "# features = category_features_df\n",
        "print(full_feature_join)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      1category_features  2category_features  ...  1030  1031\n",
            "0                                                             ...            \n",
            "13685534557686295101                 0.0                 0.0  ...   0.0   0.0\n",
            "764015621929367586                   1.0                 1.0  ...   0.0   0.0\n",
            "10846552445983457719                 0.0                 0.0  ...   0.0   0.0\n",
            "5087506707876194815                  0.0                 0.0  ...   0.0   0.0\n",
            "9094535307341385563                  0.0                 0.0  ...   0.0   0.0\n",
            "...                                  ...                 ...  ...   ...   ...\n",
            "16892862651199510638                 0.0                 0.0  ...   0.0   0.0\n",
            "7229716827056183679                  0.0                 0.0  ...   0.0   0.0\n",
            "4626564123199390189                  0.0                 0.0  ...   0.0   0.0\n",
            "2978566027619600648                  0.0                 0.0  ...   0.0   0.0\n",
            "9744251496066876000                  0.0                 0.0  ...   0.0   0.0\n",
            "\n",
            "[808944 rows x 1706 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCBshhYpnHfC",
        "colab_type": "text"
      },
      "source": [
        "## Dimensionality Reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IaScgb-7nKii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "outputId": "8e8ff0bd-4316-4398-d9a2-011a5f683cbd"
      },
      "source": [
        "svd = sklearn.decomposition.TruncatedSVD(n_components=100, n_iter=10)\n",
        "svd.fit(full_feature_join[:10000])\n",
        "print(svd.explained_variance_ratio_)\n",
        "print(svd.explained_variance_ratio_.sum())\n",
        "print(svd.singular_values_)\n",
        "\n",
        "reduced_features = svd.transform(full_feature_join)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.06401376 0.04622242 0.03231303 0.02621636 0.02257431 0.01852799\n",
            " 0.0186303  0.01779371 0.01739593 0.01666311 0.0150197  0.0143001\n",
            " 0.01278896 0.01234873 0.0116726  0.01147952 0.01105916 0.00990296\n",
            " 0.00961921 0.00929172 0.0087435  0.00855063 0.00827113 0.00810978\n",
            " 0.00806891 0.00790611 0.00728912 0.00715424 0.00696381 0.00653401\n",
            " 0.00640232 0.00630214 0.00614893 0.00613491 0.00598965 0.00591875\n",
            " 0.00553692 0.00539549 0.00524816 0.00511368 0.00500888 0.00478776\n",
            " 0.00469004 0.00467389 0.00455159 0.00444006 0.00443729 0.0043122\n",
            " 0.00424332 0.00412112 0.00400106 0.00395953 0.00391999 0.00388471\n",
            " 0.00378563 0.0036996  0.00358337 0.00350389 0.00342093 0.00339636\n",
            " 0.00332248 0.00331422 0.00320684 0.0031823  0.00314515 0.00306975\n",
            " 0.00302897 0.00298353 0.00294386 0.00289755 0.00286698 0.00282751\n",
            " 0.00278782 0.0027293  0.00270976 0.00271416 0.00267104 0.00264891\n",
            " 0.00263675 0.00259499 0.00255405 0.00254637 0.00251334 0.00248847\n",
            " 0.00248535 0.0024536  0.00241769 0.00238761 0.00237204 0.00232595\n",
            " 0.00231221 0.00226952 0.00226065 0.00224632 0.00222359 0.00221178\n",
            " 0.00217034 0.00216523 0.00213544 0.0020967 ]\n",
            "0.720955122023959\n",
            "[54.88183238 37.47043174 32.10386876 28.97126205 26.23616244 24.16271208\n",
            " 23.64516448 23.11467837 22.92934554 22.38057638 21.28537585 20.72010778\n",
            " 19.69153895 19.32149849 18.76065249 18.53710336 18.26068335 17.33324307\n",
            " 17.01534232 16.67808615 16.17802968 16.01585756 15.7578753  15.62102594\n",
            " 15.54689034 15.38676014 14.79899045 14.67424429 14.45015047 13.98516256\n",
            " 13.88406386 13.7362569  13.64779797 13.55375071 13.39319323 13.31770234\n",
            " 12.87792617 12.72650418 12.5662928  12.3726325  12.28306671 11.97689429\n",
            " 11.86874668 11.82813965 11.67352601 11.55081405 11.52667405 11.37428649\n",
            " 11.27110491 11.12841833 10.96167646 10.88729943 10.83413106 10.78326585\n",
            " 10.6502538  10.52669904 10.36137768 10.25462088 10.12428061 10.09349039\n",
            "  9.9920397   9.962676    9.79821929  9.76401854  9.70269342  9.58690814\n",
            "  9.53237284  9.45171989  9.38888077  9.31376377  9.26859859  9.20979517\n",
            "  9.13790829  9.04281202  9.02647628  9.01354581  8.94237402  8.90679564\n",
            "  8.88530465  8.81621221  8.74352349  8.73067337  8.68806405  8.63993899\n",
            "  8.63377469  8.5705184   8.50817016  8.45404542  8.435153    8.34549028\n",
            "  8.31950357  8.2452927   8.22803733  8.20090604  8.16081891  8.1378349\n",
            "  8.06537529  8.05128051  7.99693005  7.92373407]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfhmbxNHn9hX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e1f05c0f-8627-4e03-d45c-90b714d3bc1a"
      },
      "source": [
        "print(reduced_features)\n",
        "\n",
        "sparse_data = pd.DataFrame(data=reduced_features, index=full_feature_join.index, columns=range(np.shape(reduced_features)[1]))\n",
        "print(sparse_data)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.13267225e-02  9.55330856e-02  2.59727273e-01 ... -2.36151409e-04\n",
            "   4.54597035e-03 -4.69870046e-03]\n",
            " [ 1.23233228e+00 -8.14231652e-02  3.90605807e-03 ...  1.98890213e-02\n",
            "  -2.38637775e-02  3.95002210e-02]\n",
            " [ 9.28904313e-02  9.56332376e-02  2.86148240e-01 ... -1.07869175e-02\n",
            "   6.39112267e-03  1.83483506e-02]\n",
            " ...\n",
            " [ 4.97493302e-04  1.59515213e-03  1.81023944e-03 ... -9.59748019e-03\n",
            "   3.92670295e-03 -1.38205766e-03]\n",
            " [ 9.58401906e-01 -2.30705297e-01 -1.30523489e-01 ...  9.49070769e-02\n",
            "  -7.56302242e-02 -3.66692276e-02]\n",
            " [ 6.43466070e-03  2.86405002e-03  5.11493682e-03 ...  3.28887361e-01\n",
            "   2.94411529e-01 -1.22057421e-01]]\n",
            "                                0            1   ...           98           99\n",
            "0                                                ...                          \n",
            "13685534557686295101    213.267225   955.330856  ...    45.459704   -46.987005\n",
            "764015621929367586    12323.322800  -814.231652  ...  -238.637775   395.002210\n",
            "10846552445983457719    928.904313   956.332376  ...    63.911227   183.483506\n",
            "5087506707876194815   10444.494250 -2263.811109  ...   130.592058   386.553534\n",
            "9094535307341385563   10412.988152 -1814.069795  ...  -228.319122    80.062717\n",
            "...                            ...          ...  ...          ...          ...\n",
            "16892862651199510638    137.176248   284.730015  ...   406.149957   538.039497\n",
            "7229716827056183679      68.572131   287.243308  ...     3.036819  -115.000581\n",
            "4626564123199390189       4.974933    15.951521  ...    39.267029   -13.820577\n",
            "2978566027619600648    9584.019058 -2307.052968  ...  -756.302242  -366.692276\n",
            "9744251496066876000      64.346607    28.640500  ...  2944.115291 -1220.574214\n",
            "\n",
            "[808944 rows x 100 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6InV-GK0e49l",
        "colab_type": "text"
      },
      "source": [
        "# Read Regression Targets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzWperFWfA4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_folder = '/content/gdrive/My Drive/vc_modeling/regression_targets/'\n",
        "marks = [200, 500, 1000, 2000]\n",
        "\n",
        "regression_marks = {}\n",
        "for mark in marks:\n",
        "  regression_marks[mark] = pd.read_csv(target_folder + str(mark) + '.csv')[['hash', 'initial_valuation', 'log_valuation_factor']].set_index('hash')\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9hQhkQcY4Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "outputId": "49b917bf-a1ef-4607-d3aa-f3b3758c4a05"
      },
      "source": [
        "mark_data = regression_marks[200] # pd.read_pickle(\"/content/gdrive/My Drive/vc_modeling/regression_targets/200.pkl\")\n",
        "# mark_data = mark_data[mark_data['log_valuation_factor'] > 0]\n",
        "print(mark_data)\n",
        "print(category_features_df)\n",
        "print(np.count_nonzero(mark_data.index.isin(region_features_df.index)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                      initial_valuation  log_valuation_factor\n",
            "hash                                                         \n",
            "13360469805707984821          3000000.0              0.000000\n",
            "7551169957279540846          45000000.0              0.266595\n",
            "17638643441008354186          2280520.0              0.000000\n",
            "14753292511968607343          3000000.0              0.000000\n",
            "18303053280205650499         20400150.0              0.000000\n",
            "...                                 ...                   ...\n",
            "1328871151505778773            600000.0              0.183442\n",
            "16862606919743425243           162360.0              0.000000\n",
            "14711304329054892014         65500000.0              0.344393\n",
            "17393885764651115266         20000000.0             -0.189295\n",
            "12723450708549610702            75000.0              0.000000\n",
            "\n",
            "[49489 rows x 2 columns]\n",
            "                         0    1    2    3    4    ...  671  672  673  674  675\n",
            "0       13685534557686295101  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "1         764015621929367586  1.0  1.0  1.0  1.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "2       10846552445983457719  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "3        5087506707876194815  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "4        9094535307341385563  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "...                      ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
            "963962   9744251496066876000  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "963963  13650824445832434760  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "963964  15062640940509416191  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "963965   9929788675484222851  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "963966  12539503581336717831  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0\n",
            "\n",
            "[963967 rows x 676 columns]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnfflhAPyChF",
        "colab_type": "text"
      },
      "source": [
        "# Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57NUdx-Xx-9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train Models\n",
        "import sklearn.metrics\n",
        "\n",
        "def regression_analysis(model, train_data, train_values, test_data, test_values):\n",
        "    predicted_train_values = model.predict(train_data)\n",
        "    predicted_test_values = model.predict(test_data)\n",
        "\n",
        "    print(\"Sample values: \", predicted_test_values[:5], test_values[:5])\n",
        "\n",
        "    train_mse = sklearn.metrics.mean_squared_error(train_values, predicted_train_values)\n",
        "    test_mse = sklearn.metrics.mean_squared_error(test_values, predicted_test_values)\n",
        "    train_explained_variance = sklearn.metrics.explained_variance_score(train_values, predicted_train_values)\n",
        "    test_explained_variance = sklearn.metrics.explained_variance_score(test_values, predicted_test_values)\n",
        "\n",
        "    print(\"Train MSE: \", train_mse)\n",
        "    print(\"Train Explained Variance Score: \", train_explained_variance)\n",
        "    print(\"Test MSE: \", test_mse)\n",
        "    print(\"Test Explained Variance Score: \", test_explained_variance)\n",
        "\n",
        "    return model\n",
        "\n",
        "def classification_analysis(model, train_data, train_values, test_data, test_values):\n",
        "    train_values_predicted = model.predict(train_data)\n",
        "    train_prediction = train_values_predicted > 0.00001\n",
        "    train_prediction = train_prediction.astype(np.int32)\n",
        "\n",
        "    test_values_predicted = model.predict(test_data)\n",
        "    test_prediction = test_values_predicted > 0.00001\n",
        "    test_prediction = test_prediction.astype(np.int32)\n",
        "\n",
        "    train_labels = train_values > 0.00001\n",
        "    train_labels = train_labels.astype(np.int32)\n",
        "\n",
        "    test_labels = test_values > 0.00001\n",
        "    test_labels = test_labels.astype(np.int32)\n",
        "\n",
        "    confusion_matrix_large = pd.DataFrame(sklearn.metrics.confusion_matrix(test_labels, test_prediction, labels=[1, 0]),\n",
        "                                    columns=['positive', 'negative'], index=['Truth is +', 'Truth is -'])\n",
        "    print(\"Confusion:\\n\", confusion_matrix_large)\n",
        "    test_acc = sum(test_labels==test_prediction)/len(test_labels)\n",
        "    print(\"Test accuracy: \", test_acc)\n",
        "    train_acc = sum(train_labels==train_prediction)/len(train_labels)\n",
        "    print(\"Train accuracy: \", train_acc)\n",
        "\n",
        "\n",
        "    # # Use the metrics.roc_curve function to get the true positive rate (tpr) and false positive rate (fpr)\n",
        "    # fpr, tpr, thresholds = sklearn.metrics.roc_curve(test_labels, test_probabilities)\n",
        "\n",
        "    # # Get the area under the curve (AUC)\n",
        "    # auc = np.mean(cross_val_score(model, test_data, test_labels, scoring=\"roc_auc\", cv=5))\n",
        "    # print(\"AUC = \" , str(round(auc, 2)))\n",
        "\n",
        "    # # Plot the ROC curve\n",
        "\n",
        "    # plt.xlabel(\"False positive rate (fpr)\")\n",
        "    # plt.ylabel(\"True positive rate (tpr)\")\n",
        "    # plt.plot(fpr, tpr, label='model')\n",
        "    # plt.plot([0, 1], [0, 1], color='k', label=\"random\")\n",
        "    # plt.legend(loc='best')\n",
        "\n",
        "    # plt.figure()\n",
        "    # plt.xlabel(\"Recall\")\n",
        "    # plt.ylabel(\"Precision\")\n",
        "    # precision, recall, _ = sklearn.metrics.precision_recall_curve(test_labels, test_probabilities)\n",
        "    # plt.plot(recall, precision)\n",
        "\n",
        "def train_model_over_mark(model, input_data, mark, filter_unknown=True):\n",
        "  print(\"\\nRESULTS FOR\", str(mark), \"DAY MARK:\\n\")\n",
        "  # print(features)\n",
        "  mark_data = regression_marks[mark]\n",
        "  # print(mark_data)\n",
        "  if filter_unknown:\n",
        "    mark_data = mark_data[mark_data['log_valuation_factor'] != 0]\n",
        "  # Select the data that we have regression targets for\n",
        "\n",
        "  data = input_data[input_data.index.isin(mark_data.index)]\n",
        "\n",
        "  # Select the column with log_valuation_factor.\n",
        "  values = mark_data[mark_data.index.isin(input_data.index)]['log_valuation_factor']\n",
        "\n",
        "  data = scipy.sparse.coo_matrix(data.values)\n",
        "\n",
        "  train_data, test_data, train_values, test_values = sklearn.model_selection.train_test_split(data, values, test_size=0.25)\n",
        "  print(\"Trained on\", str(np.shape(train_data)[0]), \"rows.\")\n",
        "  \n",
        "  model.fit(train_data, train_values)\n",
        "  regression_analysis(model, train_data, train_values, test_data, test_values)\n",
        "  classification_analysis(model, train_data, train_values, test_data, test_values)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol1UlbPc-Njh",
        "colab_type": "text"
      },
      "source": [
        "## Lasso"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4zrYwJg-M0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ecf2c34-28ee-412d-e004-ae75bdd45f6c"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "for mark in marks:\n",
        "  lasso_model = sklearn.linear_model.LassoCV()\n",
        "  train_model_over_mark(lasso_model, sparse_data, mark, filter_unknown=False)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RESULTS FOR 200 DAY MARK:\n",
            "\n",
            "Trained on 36492 rows.\n",
            "Sample values:  [0.12834459 0.12834459 0.12834459 0.12834459 0.12834459] hash\n",
            "9635054904118854714    1.057767\n",
            "4338174792098848232   -0.344257\n",
            "5902977640969687409    0.000000\n",
            "1429516911200635092    0.000000\n",
            "9015320471241621766    0.927342\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  0.35975036859066006\n",
            "Train Explained Variance Score:  0.0\n",
            "Test MSE:  0.3857910338084795\n",
            "Test Explained Variance Score:  0.0\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      3309         0\n",
            "Truth is -      8856         0\n",
            "Test accuracy:  0.2720098643649815\n",
            "Train accuracy:  0.26172859804888743\n",
            "\n",
            "RESULTS FOR 500 DAY MARK:\n",
            "\n",
            "Trained on 28341 rows.\n",
            "Sample values:  [0.24249954 0.24249954 0.24249954 0.24249954 0.24249954] hash\n",
            "16286736773237133362    0.000000\n",
            "10209373373140010738    0.000000\n",
            "12431266135092031899    0.000000\n",
            "2834347387388543431     0.000000\n",
            "13067619211706607034    1.140273\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  0.7568782269444762\n",
            "Train Explained Variance Score:  0.0\n",
            "Test MSE:  0.7231448126072378\n",
            "Test Explained Variance Score:  0.0\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      2554         0\n",
            "Truth is -      6894         0\n",
            "Test accuracy:  0.2703217612193057\n",
            "Train accuracy:  0.27126777460216644\n",
            "\n",
            "RESULTS FOR 1000 DAY MARK:\n",
            "\n",
            "Trained on 17580 rows.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-07754760550b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmark\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmarks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mlasso_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLassoCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mtrain_model_over_mark\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmark\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_unknown\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-37-9bc51815871a>\u001b[0m in \u001b[0;36mtrain_model_over_mark\u001b[0;34m(model, input_data, mark, filter_unknown)\u001b[0m\n\u001b[1;32m     84\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trained on\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rows.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m   \u001b[0mregression_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0mclassification_analysis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlasso_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 for train, test in folds)\n\u001b[1;32m   1183\u001b[0m         mse_paths = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0;32m-> 1184\u001b[0;31m                              **_joblib_parallel_args(prefer=\"threads\"))(jobs)\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0mmse_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_l1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mmean_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 253\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36m_path_residuals\u001b[0;34m(X, y, train, test, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;31m# X is copied and a reference is kept here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m     \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpath_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1010\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36mlasso_path\u001b[0;34m(X, y, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, **params)\u001b[0m\n\u001b[1;32m    261\u001b[0m                      \u001b[0malphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m                      \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m                      positive=positive, return_n_iter=return_n_iter, **params)\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    458\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_sparse_scaling\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m                 max_iter, tol, rng, random, positive)\n\u001b[0m\u001b[1;32m    461\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m             model = cd_fast.enet_coordinate_descent_multi_task(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77ksr5r4cuc0",
        "colab_type": "text"
      },
      "source": [
        "## Decision Tree Regressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5PRMVseeLBU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39be3071-d098-4d41-b30c-6a143a6fd6a5"
      },
      "source": [
        "import sklearn.tree\n",
        "\n",
        "tree_model = sklearn.tree.DecisionTreeRegressor()\n",
        "for mark in marks:\n",
        "  train_model_over_mark(tree_model, sparse_data, mark, filter_unknown=True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RESULTS FOR 200 DAY MARK:\n",
            "\n",
            "Trained on 13498 rows.\n",
            "Sample values:  [ 0.38957124 -0.38987463 -0.01650987  0.96085846 -0.04752007] hash\n",
            "1539187771468936227    -0.021936\n",
            "8878152371675513997    -0.059824\n",
            "4651261723488561146    -0.100106\n",
            "15578431125805125417    0.686896\n",
            "4326862306739552201     0.033297\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  0.258279791386746\n",
            "Train Explained Variance Score:  0.7176740351334385\n",
            "Test MSE:  1.7229975386796281\n",
            "Test Explained Variance Score:  -0.9190296137568179\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      2368       806\n",
            "Truth is -      1007       319\n",
            "Test accuracy:  0.5971111111111111\n",
            "Train accuracy:  0.911320195584531\n",
            "\n",
            "RESULTS FOR 500 DAY MARK:\n",
            "\n",
            "Trained on 10535 rows.\n",
            "Sample values:  [0.85202955 1.47583344 0.37547356 4.79332762 0.54269165] hash\n",
            "3562850683372544024    -0.075691\n",
            "17460468714696648826    0.661261\n",
            "6409568727647815949     1.386294\n",
            "15904630325921400176    0.724988\n",
            "6396253215314146524     0.730672\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  0.4594320198640676\n",
            "Train Explained Variance Score:  0.7380373067204835\n",
            "Test MSE:  3.307460371237791\n",
            "Test Explained Variance Score:  -0.9018392872632124\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      1930       625\n",
            "Truth is -       749       208\n",
            "Test accuracy:  0.6087699316628702\n",
            "Train accuracy:  0.9192216421452302\n",
            "\n",
            "RESULTS FOR 1000 DAY MARK:\n",
            "\n",
            "Trained on 6560 rows.\n",
            "Sample values:  [ 2.61887102  0.46315904  0.62872501  1.39639199 -2.7080502 ] hash\n",
            "8925439769631664767     2.772589\n",
            "5821295784579167330    -0.801325\n",
            "7162168158502996826     2.187011\n",
            "17917148279403816028    4.199705\n",
            "5826696755878674873    -0.790092\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  0.5286528231253164\n",
            "Train Explained Variance Score:  0.7797414696594078\n",
            "Test MSE:  4.855960648283887\n",
            "Test Explained Variance Score:  -0.9003955810150599\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      1235       356\n",
            "Truth is -       444       152\n",
            "Test accuracy:  0.6342021033379058\n",
            "Train accuracy:  0.936280487804878\n",
            "\n",
            "RESULTS FOR 2000 DAY MARK:\n",
            "\n",
            "Trained on 2553 rows.\n",
            "Sample values:  [4.40702882 0.66962556 1.78554821 0.21964325 3.6662252 ] hash\n",
            "18124453460438379715   -0.510826\n",
            "1597567116217745799     2.970511\n",
            "8205196430789307567     5.736327\n",
            "377103872990983108      1.139434\n",
            "11223525232808866652    2.525729\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  0.6331907124708881\n",
            "Train Explained Variance Score:  0.7879961900257606\n",
            "Test MSE:  6.143547577864062\n",
            "Test Explained Variance Score:  -0.914884603693547\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +       517       129\n",
            "Truth is -       175        30\n",
            "Test accuracy:  0.6427732079905993\n",
            "Train accuracy:  0.9310614962788876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyz3a63EcWxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zk-T0iO2xtaQ",
        "colab_type": "text"
      },
      "source": [
        "## SGD"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_GVqKW6xxhl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7df75621-c9bc-4814-e5db-98370988f24d"
      },
      "source": [
        "import sklearn.linear_model\n",
        "\n",
        "sgd = sklearn.linear_model.SGDRegressor()\n",
        "\n",
        "for mark in marks:\n",
        "  train_model_over_mark(sgd, sparse_data, mark, filter_unknown=True)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RESULTS FOR 200 DAY MARK:\n",
            "\n",
            "Trained on 13498 rows.\n",
            "Sample values:  [ 5.42544844e+12 -1.51932148e+10  5.70230395e+11  4.23076384e+12\n",
            "  7.59364846e+12] hash\n",
            "13439980885430424585   -0.466044\n",
            "14540037555001281782   -0.033966\n",
            "3250329110132211562     0.143256\n",
            "1079725013699894949     0.113257\n",
            "16742286512715274565    1.480738\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  7.768540844264619e+24\n",
            "Train Explained Variance Score:  -8.61307789408609e+24\n",
            "Test MSE:  7.546458874701259e+24\n",
            "Test Explained Variance Score:  -7.826575030676455e+24\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      1664      1540\n",
            "Truth is -       656       640\n",
            "Test accuracy:  0.512\n",
            "Train accuracy:  0.5094828863535339\n",
            "\n",
            "RESULTS FOR 500 DAY MARK:\n",
            "\n",
            "Trained on 10535 rows.\n",
            "Sample values:  [ 2.53392560e+12 -3.07801368e+12 -1.86892792e+12  2.61516547e+12\n",
            " -9.23074241e+11] hash\n",
            "5574984909912519612     0.758729\n",
            "12648439801360052427    0.911952\n",
            "16977089313544495306    0.133531\n",
            "5046154830404202752    -1.007901\n",
            "15200038521680144351    0.665578\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  8.526565620541874e+24\n",
            "Train Explained Variance Score:  -4.674098906080576e+24\n",
            "Test MSE:  8.94745787420293e+24\n",
            "Test Explained Variance Score:  -4.842778988449973e+24\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      1004      1562\n",
            "Truth is -       341       605\n",
            "Test accuracy:  0.4581435079726651\n",
            "Train accuracy:  0.44110109159943045\n",
            "\n",
            "RESULTS FOR 1000 DAY MARK:\n",
            "\n",
            "Trained on 6560 rows.\n",
            "Sample values:  [ 1.15881528e+12  7.00668132e+11  7.08273671e+11 -6.21367851e+11\n",
            " -5.20803323e+12] hash\n",
            "16417251041797539292    1.963443\n",
            "2660726294024488060    -0.783760\n",
            "3361312383571880414     0.477116\n",
            "9464515334465522695    -1.897120\n",
            "16408030568706521103    0.506109\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  1.5928162994113517e+25\n",
            "Train Explained Variance Score:  -6.418591939844246e+24\n",
            "Test MSE:  1.5760201719551304e+25\n",
            "Test Explained Variance Score:  -6.674064861122513e+24\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +       931       701\n",
            "Truth is -       307       248\n",
            "Test accuracy:  0.5390946502057613\n",
            "Train accuracy:  0.5367378048780488\n",
            "\n",
            "RESULTS FOR 2000 DAY MARK:\n",
            "\n",
            "Trained on 2553 rows.\n",
            "Sample values:  [-1.79571063e+12 -1.17392709e+13  3.21160823e+12 -1.12750377e+13\n",
            " -1.59301757e+12] hash\n",
            "13107414460519288646   -0.094911\n",
            "14964744872517040034    1.897120\n",
            "8457447552745680874     1.162769\n",
            "8037092525403216537     0.988924\n",
            "9240809964899370903     0.314711\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  2.7046942043455e+25\n",
            "Train Explained Variance Score:  -8.887850256118173e+24\n",
            "Test MSE:  2.3906222482809856e+25\n",
            "Test Explained Variance Score:  -7.842442458159176e+24\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +       314       332\n",
            "Truth is -       103       102\n",
            "Test accuracy:  0.4888366627497062\n",
            "Train accuracy:  0.4770857814336075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmcPRYYmzrp-",
        "colab_type": "text"
      },
      "source": [
        "# SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE03MWnSztYb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ca779d9-23b8-47e7-9fc8-a99c2404dbf2"
      },
      "source": [
        "import sklearn.svm\n",
        "\n",
        "for mark in marks:\n",
        "  svm = sklearn.svm.SVR()\n",
        "  train_model_over_mark(svm, sparse_data, mark, filter_unknown=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "RESULTS FOR 200 DAY MARK:\n",
            "\n",
            "Trained on 13498 rows.\n",
            "Sample values:  [1.05813049 1.05813049 1.05813049 1.05813049 1.05813049] hash\n",
            "7605692520027625648     1.791759\n",
            "2220049177037197525    -0.304924\n",
            "18279224463993360850    0.124412\n",
            "10247127945768244428    0.341429\n",
            "3242767193354031088     0.777820\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  1.4096404167477183\n",
            "Train Explained Variance Score:  0.0\n",
            "Test MSE:  1.3827565736857397\n",
            "Test Explained Variance Score:  2.220446049250313e-16\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      3183         0\n",
            "Truth is -      1317         0\n",
            "Test accuracy:  0.7073333333333334\n",
            "Train accuracy:  0.716921025337087\n",
            "\n",
            "RESULTS FOR 500 DAY MARK:\n",
            "\n",
            "Trained on 10535 rows.\n",
            "Sample values:  [1.05813049 1.05813049 1.05813049 1.05813049 1.05813049] hash\n",
            "13765974736818171632    0.916291\n",
            "16458525995278093477    1.832581\n",
            "11970094808217328200   -0.415780\n",
            "8306724763510158031     0.415741\n",
            "7138478480837883586     1.059293\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  1.9526887544699194\n",
            "Train Explained Variance Score:  0.0\n",
            "Test MSE:  1.817228361095423\n",
            "Test Explained Variance Score:  0.0\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      2585         0\n",
            "Truth is -       927         0\n",
            "Test accuracy:  0.7360478359908884\n",
            "Train accuracy:  0.7268153773137161\n",
            "\n",
            "RESULTS FOR 1000 DAY MARK:\n",
            "\n",
            "Trained on 6560 rows.\n",
            "Sample values:  [1.05813049 1.05813049 1.05813049 1.05813049 1.05813049] hash\n",
            "7920177346872242696    -2.197225\n",
            "2570710947836918441     1.098612\n",
            "15035257300000526640    0.105125\n",
            "4071855429613857694     0.045462\n",
            "5110690378023350459    -0.405465\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  2.516539979778967\n",
            "Train Explained Variance Score:  0.0\n",
            "Test MSE:  2.3524952920495243\n",
            "Test Explained Variance Score:  0.0\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +      1610         0\n",
            "Truth is -       577         0\n",
            "Test accuracy:  0.7361682670324645\n",
            "Train accuracy:  0.7428353658536585\n",
            "\n",
            "RESULTS FOR 2000 DAY MARK:\n",
            "\n",
            "Trained on 2553 rows.\n",
            "Sample values:  [1.05813049 1.05813049 1.05813049 1.05813049 1.05813049] hash\n",
            "10410717754288246283   -0.405465\n",
            "11701291077335966719    0.405465\n",
            "3971003734211618095    -0.405465\n",
            "13092431046120504300   -1.560648\n",
            "737888817662873879      0.051662\n",
            "Name: log_valuation_factor, dtype: float64\n",
            "Train MSE:  3.0283158781534216\n",
            "Train Explained Variance Score:  0.0\n",
            "Test MSE:  3.0860700782577046\n",
            "Test Explained Variance Score:  0.0\n",
            "Confusion:\n",
            "             positive  negative\n",
            "Truth is +       645         0\n",
            "Truth is -       206         0\n",
            "Test accuracy:  0.7579318448883666\n",
            "Train accuracy:  0.7516647081864474\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}