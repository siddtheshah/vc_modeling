{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "category_features.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQCQWJnUkFLMnHw+GjVCFp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddtheshah/vc_modeling/blob/master/region_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLj02yHu8Fm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "d347629c-0a8d-4283-8b24-668ddc9e3d52"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install cityhash\n",
        "import cityhash\n",
        "\n",
        "from copy import deepcopy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: cityhash in /usr/local/lib/python3.6/dist-packages (0.2.3.post9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNCUUReS8P_O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0fcbd4f9-47ed-4513-b3b5-e1767cb3789a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLIkmx-Q8Sm0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "f3c16234-e4dd-4095-ec0d-01abb8dd6ead"
      },
      "source": [
        "file_names = os.listdir(\"/content/gdrive/My Drive/vc_modeling/data/crunchbase_bulk_export/\")\n",
        "df_names = [x[:-4] for x in file_names]\n",
        "print(df_names)\n",
        "\n",
        "dfs = [pd.read_csv(\"/content/gdrive/My Drive/vc_modeling/data/crunchbase_bulk_export/\"+x) for x in file_names]\n",
        "df_dict = dict(zip(df_names, dfs))\n",
        "print(df_dict.keys())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['category_groups', 'funding_rounds', 'people', 'checksum', 'people_descriptions', 'investors', 'organization_descriptions', 'investment_partners', 'event_appearances', 'organizations', 'org_parents', 'jobs', 'acquisitions', 'funds', 'ipos', 'degrees', 'investments', 'events']\n",
            "dict_keys(['category_groups', 'funding_rounds', 'people', 'checksum', 'people_descriptions', 'investors', 'organization_descriptions', 'investment_partners', 'event_appearances', 'organizations', 'org_parents', 'jobs', 'acquisitions', 'funds', 'ipos', 'degrees', 'investments', 'events'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTkfMfnE8Xl6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "b9f72a68-3060-4790-9966-e9c3c19b4571"
      },
      "source": [
        "import collections\n",
        "\n",
        "org_info = df_dict['organizations']\n",
        "\n",
        "# Filter down the data purely to investees\n",
        "org_info = org_info[org_info['primary_role'] == 'company']\n",
        "\n",
        "# Select organization data\n",
        "# Clean the df\n",
        "\n",
        "comma_sep_list_vars = ['category_list', 'category_groups_list']\n",
        "categorical_vars = ['region']\n",
        "other_vars = ['uuid']\n",
        "org_info_selected = org_info[other_vars + categorical_vars + comma_sep_list_vars]\n",
        "org_info_selected = org_info_selected.dropna()\n",
        "org_info_selected = org_info_selected.reset_index(drop=True)\n",
        "\n",
        "vocabulary = collections.Counter()\n",
        "\n",
        "iter = 0\n",
        "test_stop = -1\n",
        "total_rows = np.shape(org_info_selected)[0]\n",
        "print(\"Processing \", total_rows, \" rows.\")\n",
        "for (i, row) in org_info_selected.iterrows():\n",
        "  if iter == test_stop:\n",
        "    break\n",
        "  iter += 1\n",
        "  if iter % 100000 == 0:\n",
        "    print(iter, \" of \", total_rows)\n",
        "\n",
        "  for col, _ in row.iteritems():\n",
        "    if col in comma_sep_list_vars:\n",
        "      # Break categories into unigrams\n",
        "      token_lists = [x.split(' ') for x in row[col].strip().split(',')]\n",
        "      tokens = []\n",
        "      for token_list in token_lists:\n",
        "        for token in token_list:\n",
        "          tokens.append(token)\n",
        "\n",
        "      for token in tokens:\n",
        "        vocabulary[token] += 1\n",
        "\n",
        "# Filter low count words\n",
        "low_count_threshold = 15\n",
        "keys_to_remove = []\n",
        "for word, count in vocabulary.items():\n",
        "  if count < low_count_threshold:\n",
        "    keys_to_remove.append(word)\n",
        "\n",
        "for key in keys_to_remove:\n",
        "  del vocabulary[key]\n",
        "\n",
        "# Now rank and filter by document frequency. The top 5% gets dropped due to being extremely low information.\n",
        "key_list = list(vocabulary.keys())\n",
        "fraction_to_drop = .15\n",
        "chop = sorted(key_list, key=lambda x: vocabulary[x])[-int(fraction_to_drop*len(key_list)):]\n",
        "for key in chop:\n",
        "  del vocabulary[key]\n",
        "\n",
        "# Create index to word mapping\n",
        "word_to_index = {}\n",
        "word_index = 0\n",
        "for word, count in vocabulary.items():\n",
        "  word_to_index[word] = word_index\n",
        "  word_index += 1\n",
        "\n",
        "print(word_to_index)\n",
        "vocabulary_size = word_index"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing  808944  rows.\n",
            "100000  of  808944\n",
            "200000  of  808944\n",
            "300000  of  808944\n",
            "400000  of  808944\n",
            "500000  of  808944\n",
            "600000  of  808944\n",
            "700000  of  808944\n",
            "800000  of  808944\n",
            "{'Computing': 0, 'Collaboration': 1, 'CRM': 2, 'Developer': 3, 'Tools': 4, 'Project': 5, 'Streaming': 6, 'File': 7, 'Sharing': 8, 'Hosting': 9, 'Photography': 10, 'Blogging': 11, 'SMS': 12, 'Personalization': 13, '3D': 14, 'EBooks': 15, 'Subscription': 16, 'Auctions': 17, 'Marketplace': 18, 'Search': 19, 'Engine': 20, 'Big': 21, 'Online': 22, 'Portals': 23, 'Location': 24, 'Based': 25, 'Time': 26, 'Navigation': 27, 'Mapping': 28, 'Cyber': 29, 'TV': 30, 'Mining': 31, 'Embedded': 32, 'Hedge': 33, 'Funds': 34, 'Precious': 35, 'Metals': 36, 'Broadcasting': 37, 'Contact': 38, 'Communications': 39, 'Infrastructure': 40, 'Language': 41, 'Processing': 42, 'Public': 43, 'Relations': 44, 'Knowledge': 45, 'Virtual': 46, 'Currency': 47, 'Delivery': 48, 'Film': 49, 'Brand': 50, 'Production': 51, 'Machine': 52, 'Personal': 53, 'Industry': 54, 'Crowdfunding': 55, 'Creators': 56, 'VoIP': 57, 'GPS': 58, 'Bookmarking': 59, 'Document': 60, 'Browsers': 61, 'Predictive': 62, 'Risk': 63, 'Games': 64, 'Browser': 65, 'Extensions': 66, 'Devices': 67, 'Database': 68, 'Dating': 69, 'Beauty': 70, 'Fitness': 71, 'Chat': 72, 'APIs': 73, 'Email': 74, 'Wireless': 75, 'Forums': 76, 'Celebrity': 77, 'Innovation': 78, 'Market': 79, 'Research': 80, 'Radio': 81, 'PaaS': 82, 'Facebook': 83, 'Ticketing': 84, 'Environmental': 85, 'Life': 86, 'Android': 87, 'Photo': 88, 'PC': 89, 'Reality': 90, 'World': 91, 'Private': 92, 'Networking': 93, 'Podcast': 94, 'Coupons': 95, 'Local': 96, 'Hotel': 97, 'Pet': 98, 'Technical': 99, 'Support': 100, 'Exchanges': 101, 'Stock': 102, 'Venture': 103, 'Capital': 104, 'Ad': 105, 'Exchange': 106, 'Discovery': 107, 'Ediscovery': 108, 'Association': 109, 'Event': 110, 'Integration': 111, 'Physical': 112, 'Flash': 113, 'Storage': 114, 'Concerts': 115, 'Property': 116, 'Smart': 117, 'Nightlife': 118, 'Restaurants': 119, 'Vision': 120, 'Drones': 121, 'National': 122, 'Freelance': 123, 'Peer': 124, 'to': 125, 'Employment': 126, 'Classifieds': 127, 'Reviews': 128, 'Cooking': 129, 'Recipes': 130, 'Leisure': 131, 'Teenagers': 132, 'WebOS': 133, 'Point': 134, 'Sale': 135, 'Promotion': 136, 'Shipping': 137, 'E-Learning': 138, 'Universities': 139, 'Virtualization': 140, 'Identity': 141, 'App': 142, 'Crowdsourcing': 143, 'on': 144, 'Demand': 145, 'Creative': 146, 'Agency': 147, 'Semantic': 148, 'Accounting': 149, 'Angel': 150, 'Investment': 151, 'Transaction': 152, 'Distribution': 153, 'Art': 154, 'Children': 155, 'Animation': 156, 'IT': 157, 'Gift': 158, 'Toys': 159, 'GreenTech': 160, 'Outdoors': 161, 'Recreation': 162, 'Recycling': 163, 'MMO': 164, 'Tobacco': 165, 'Alumni': 166, 'Career': 167, 'Planning': 168, 'Open': 169, 'Source': 170, 'Reputation': 171, 'Image': 172, 'Recognition': 173, 'Editing': 174, 'Non': 175, 'Profit': 176, 'Entrepreneurship': 177, 'Customer': 178, 'CMS': 179, 'Packaging': 180, 'Grocery': 181, 'IaaS': 182, 'Direct': 183, 'Meeting': 184, 'Independent': 185, 'Conferencing': 186, 'Small': 187, 'Medium': 188, 'Businesses': 189, 'Casual': 190, 'B2B': 191, 'Journalism': 192, 'Card': 193, 'Gambling': 194, 'Bitcoin': 195, 'Test': 196, 'Measurement': 197, 'Rental': 198, 'Safety': 199, 'Shoes': 200, 'Freemium': 201, 'Targeting': 202, 'Micro': 203, 'Credit': 204, 'Syndication': 205, 'Contests': 206, 'Lead': 207, 'Generation': 208, 'SEM': 209, \"Women's\": 210, 'Hospitality': 211, 'Reservations': 212, 'Signage': 213, 'Fantasy': 214, 'Platform': 215, 'Speech': 216, 'Psychology': 217, 'Task': 218, 'Jewelry': 219, 'Child': 220, 'Elder': 221, 'Tutoring': 222, 'Family': 223, 'Advice': 224, 'Parenting': 225, 'Asset': 226, 'Decor': 227, 'Google': 228, 'Systems': 229, 'mHealth': 230, 'Visualization': 231, 'Communication': 232, 'Casino': 233, 'Motion': 234, 'Capture': 235, 'InsurTech': 236, 'Wine': 237, 'And': 238, 'Spirits': 239, 'ISP': 240, 'Affiliate': 241, 'Charity': 242, 'Humanitarian': 243, 'Presentations': 244, 'Solar': 245, 'Wearables': 246, 'Architecture': 247, 'DIY': 248, 'Geospatial': 249, 'Hospital': 250, 'DSP': 251, 'Application': 252, 'Performance': 253, 'Advanced': 254, 'Materials': 255, 'Racing': 256, 'Elderly': 257, 'EdTech': 258, 'Higher': 259, 'Impact': 260, 'Clean': 261, 'Efficiency': 262, 'Cycling': 263, 'Satellite': 264, 'Augmented': 265, 'Intellectual': 266, 'Power': 267, 'Grid': 268, 'Politics': 269, 'Homeland': 270, 'Genetics': 271, 'AgTech': 272, 'Tech': 273, 'Q&A': 274, 'Commercial': 275, 'Lighting': 276, 'Wealth': 277, 'Fraud': 278, 'Detection': 279, 'Branding': 280, 'Furniture': 281, 'Spam': 282, 'Filtering': 283, 'Wedding': 284, 'Renovation': 285, 'Trading': 286, 'GovTech': 287, 'Freight': 288, 'DRM': 289, 'Interior': 290, 'Cosmetics': 291, 'Text': 292, 'Cards': 293, 'Debit': 294, 'Young': 295, 'Adults': 296, 'Corporate': 297, 'Intelligent': 298, 'Venues': 299, 'Musical': 300, 'Instruments': 301, 'Chemical': 302, 'Semiconductor': 303, 'Brewing': 304, 'Price': 305, 'Comparison': 306, 'Center': 307, 'Religion': 308, 'Wellness': 309, 'Collaborative': 310, 'Consumption': 311, 'Robotics': 312, 'Renewable': 313, 'CleanTech': 314, 'Fuel': 315, 'Oil': 316, 'Gas': 317, 'Nanotechnology': 318, 'Gamification': 319, 'Autonomous': 320, 'Vehicles': 321, 'Electric': 322, 'Vehicle': 323, 'Guides': 324, 'Battery': 325, 'Equestrian': 326, 'Accommodations': 327, 'Vacation': 328, 'Dietary': 329, 'Supplements': 330, 'Billing': 331, 'Law': 332, 'Enforcement': 333, 'Nutrition': 334, 'Funding': 335, 'Waste': 336, 'Collectibles': 337, 'Visual': 338, 'Outsourcing': 339, 'Employee': 340, 'Benefits': 341, 'Funerals': 342, 'Incubators': 343, 'Baby': 344, 'Resorts': 345, 'Building': 346, 'Material': 347, 'A/B': 348, 'Testing': 349, 'SNS': 350, 'RFID': 351, 'Biometrics': 352, 'Diagnostics': 353, 'Fleet': 354, 'Domain': 355, 'Registrar': 356, 'Electrical': 357, 'Theatre': 358, 'Residential': 359, 'Vertical': 360, 'eSports': 361, 'Textiles': 362, 'In-Flight': 363, 'Loyalty': 364, 'Programs': 365, 'Bureau': 366, 'Electronic': 367, 'Record': 368, '(EHR)': 369, 'Productivity': 370, 'Plastics': 371, 'Rubber': 372, 'Applications': 373, 'Skill': 374, 'Assessment': 375, 'Sporting': 376, 'Linux': 377, 'Workforce': 378, 'Reading': 379, 'Staffing': 380, 'Presentation': 381, 'Interaction': 382, 'CivicTech': 383, 'Server': 384, 'Scheduling': 385, 'Procurement': 386, 'Supply': 387, 'Chain': 388, 'Quantum': 389, 'Neuroscience': 390, 'Flowers': 391, 'Water': 392, 'E-Signature': 393, 'Eyewear': 394, 'Unified': 395, 'Twitter': 396, 'Coffee': 397, 'Retargeting': 398, 'Wholesale': 399, '(ICT)': 400, 'Aerospace': 401, 'Space': 402, 'Craft': 403, 'Beer': 404, 'Laundry': 405, 'Dry-cleaning': 406, 'Cause': 407, 'Auto': 408, 'Charter': 409, 'Schools': 410, 'QR': 411, 'Codes': 412, 'Improvement': 413, 'Audiobooks': 414, 'Usability': 415, 'Optical': 416, 'Cryptocurrency': 417, 'Operating': 418, 'Diabetes': 419, 'Air': 420, 'Soccer': 421, 'Blockchain': 422, 'GPU': 423, 'Organic': 424, 'Retirement': 425, 'Parking': 426, 'Cannabis': 427, 'Comics': 428, 'Handmade': 429, 'Compliance': 430, 'Clinical': 431, 'Trials': 432, 'Desktop': 433, 'Facial': 434, 'Translation': 435, 'Adult': 436, 'LGBT': 437, 'Biofuel': 438, 'CAD': 439, 'Call': 440, 'Recreational': 441, 'Emerging': 442, 'Markets': 443, 'Simulation': 444, 'Adventure': 445, 'College': 446, 'UX': 447, 'Group': 448, 'Buying': 449, 'NFC': 450, 'Nightclubs': 451, 'Coworking': 452, 'Machinery': 453, 'Tennis': 454, 'Investing': 455, 'Preparation': 456, 'Garden': 457, 'Label': 458, 'Tour': 459, 'Operator': 460, '(EDA)': 461, 'Sensor': 462, 'Resource': 463, '(ERP)': 464, 'Ride': 465, 'First': 466, 'Aid': 467, 'Fast-Moving': 468, 'Alternative': 469, 'Medicine': 470, 'Civil': 471, 'Archiving': 472, 'B2C': 473, 'Textbook': 474, 'Wired': 475, 'American': 476, 'Football': 477, 'Bakery': 478, 'Biopharma': 479, 'Economy': 480, 'Fertility': 481, 'Purification': 482, 'Windows': 483, 'Phone': 484, 'Registry': 485, 'Diving': 486, 'Courier': 487, 'Same': 488, 'Day': 489, 'Dental': 490, 'Tea': 491, 'Console': 492, 'Xbox': 493, 'Facilities': 494, 'Assistive': 495, 'Boating': 496, 'Snack': 497, 'Vending': 498, 'Concessions': 499, 'Field-Programmable': 500, 'Gate': 501, 'Array': 502, '(FPGA)': 503, 'Continuing': 504, 'Primary': 505, 'Secondary': 506, 'STEM': 507, 'Vocational': 508, 'Performing': 509, 'Arts': 510, 'Leasing': 511, 'Marine': 512, 'Assisted': 513, 'Living': 514, 'Sponsorship': 515, 'macOS': 516, 'Therapeutics': 517, 'Green': 518, 'Playstation': 519, 'Assistant': 520, 'Mineral': 521, 'Facility': 522, 'Wind': 523, 'Railroad': 524, 'Mechanical': 525, 'Outdoor': 526, \"Men's\": 527, 'Biomass': 528, 'Emergency': 529, 'Aquaculture': 530, 'Laser': 531, 'Horticulture': 532, 'Indoor': 533, 'Positioning': 534, 'Museums': 535, 'Historical': 536, 'Sites': 537, 'Car': 538, 'Quality': 539, 'Assurance': 540, 'Cell': 541, 'Golf': 542, 'Fossil': 543, 'Fuels': 544, 'Housekeeping': 545, 'Nutraceutical': 546, 'Maintenance': 547, 'Animal': 548, 'Feed': 549, 'Janitorial': 550, 'Glass': 551, 'Debt': 552, 'Collections': 553, 'Cities': 554, 'Nuclear': 555, 'Forestry': 556, 'Bioinformatics': 557, 'Intrusion': 558, 'Self-Storage': 559, 'Pollution': 560, 'Control': 561, 'Office': 562, 'Administration': 563, 'Hydroponics': 564, 'Wood': 565, 'Cosmetic': 566, 'Surgery': 567, 'Timeshare': 568, 'Homeless': 569, 'Shelter': 570, 'Underserved': 571, 'Serious': 572, 'Sex': 573, 'Basketball': 574, 'Nursing': 575, 'Landscaping': 576, 'Franchise': 577, 'Lingerie': 578, 'Assistance': 579, 'Livestock': 580, 'Farmers': 581, 'Warehousing': 582, 'Field': 583, 'Multi-level': 584, 'Hockey': 585, 'Last': 586, 'Mile': 587, 'Outpatient': 588, 'Edutainment': 589, 'MOOC': 590, 'Mall': 591, 'Taxi': 592, 'Specific': 593, 'Integrated': 594, 'Circuit': 595, '(ASIC)': 596, 'Limousine': 597, 'Penetration': 598, 'Catering': 599, 'Broker': 600, 'Trade': 601, 'Shows': 602, 'Trucks': 603, 'Hunting': 604, 'Veterinary': 605, 'Paper': 606, 'Collection': 607, 'Rehabilitation': 608, 'Swimming': 609, 'Fruit': 610, 'Ethereum': 611, 'Quantified': 612, 'Self': 613, 'Parks': 614, 'Made': 615, 'Order': 616, 'Millennials': 617, 'Winery': 618, 'Surfing': 619, 'Distillery': 620, 'Seafood': 621, 'Prediction': 622, 'Drone': 623, 'Cricket': 624, 'Confectionery': 625, 'Skiing': 626, 'Amusement': 627, 'Park': 628, 'Arcade': 629, 'Baseball': 630, 'Sailing': 631, 'Ports': 632, 'Harbors': 633, 'Timber': 634, 'Foundries': 635, 'Corrections': 636}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5YFUsxk8Z3T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "52493be5-4783-474d-cbbe-de0d00ed1821"
      },
      "source": [
        "from scipy.sparse import coo_matrix\n",
        "import collections\n",
        "\n",
        "# Load our filtered vocabulary if we've saved it on disk.\n",
        "\n",
        "row_indices = []\n",
        "col_indices = []\n",
        "data_values = []\n",
        "\n",
        "iter = 0\n",
        "test_stop = -1\n",
        "total_rows = np.shape(org_info_selected)[0]\n",
        "print(\"Processing \", total_rows, \" rows.\")\n",
        "for (i, row) in org_info_selected.iterrows():\n",
        "  if iter == test_stop:\n",
        "    break\n",
        "  iter += 1\n",
        "  if iter % 100000 == 0:\n",
        "    print(iter, \" of \", total_rows)\n",
        "\n",
        "  for col, _ in row.iteritems():\n",
        "    if col in comma_sep_list_vars:\n",
        "      # Break categories into unigrams\n",
        "      unigram_counts = collections.Counter()\n",
        "      token_lists = [x.split(' ') for x in row[col].strip().split(',')]\n",
        "      for token_list in token_lists:\n",
        "        for token in token_list:\n",
        "          unigram_counts[token] += 1\n",
        "      \n",
        "      for unigram, count in unigram_counts.items():\n",
        "        if unigram in vocabulary:\n",
        "          row_indices.append(i)\n",
        "          col_indices.append(word_to_index[unigram])\n",
        "          data_values.append(count)\n",
        "    elif col in categorical_vars:\n",
        "      value = row[col]\n",
        "      if value in vocabulary:\n",
        "        row_indices.append(i)\n",
        "        col_indices.append(word_to_index[value])\n",
        "        data_values.append(1)\n",
        "\n",
        "unclustered = coo_matrix((data_values, (row_indices, col_indices)))\n",
        "print(unclustered.toarray().shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing  808944  rows.\n",
            "100000  of  808944\n",
            "200000  of  808944\n",
            "300000  of  808944\n",
            "400000  of  808944\n",
            "500000  of  808944\n",
            "600000  of  808944\n",
            "700000  of  808944\n",
            "800000  of  808944\n",
            "(808944, 637)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJMWPc-d8oui",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "27eee96f-de90-4add-8833-1bbc6c8d6d17"
      },
      "source": [
        "import scipy.sparse\n",
        "\n",
        "companies = org_info_selected['uuid']\n",
        "\n",
        "lookup_index = []\n",
        "lookup_value = []\n",
        "\n",
        "used_hashes = set()\n",
        "\n",
        "row_indices = []\n",
        "col_indices = []\n",
        "data_values = []\n",
        "for (i, row) in companies.iteritems():\n",
        "  uuid = row\n",
        "  hash = cityhash.CityHash64(uuid)\n",
        "\n",
        "  if hash in used_hashes:  # Hash collision!\n",
        "    print(hash)\n",
        "    continue          # which shouldn't really happen\n",
        "  used_hashes.add(hash)\n",
        "\n",
        "  lookup_value.append(uuid)\n",
        "  lookup_index.append(hash)\n",
        "\n",
        "  row_indices.append(i)\n",
        "  col_indices.append(0)\n",
        "  data_values.append(hash)\n",
        "\n",
        "hashed_uuids = coo_matrix((data_values, (row_indices, col_indices)))\n",
        "print(np.shape(unclustered))\n",
        "print(np.shape(hashed_uuids))\n",
        "joined = scipy.sparse.hstack([hashed_uuids, unclustered])\n",
        "  \n",
        "## Generate company lookup\n",
        "lookup = pd.DataFrame.from_dict({'uuid':lookup_index, 'hash':data_values})\n",
        "\n",
        "lookup.to_csv('/lookup.csv')\n",
        "\n",
        "category_features = pd.DataFrame.sparse.from_spmatrix(joined)\n",
        "category_features.to_pickle('/category_features.pkl')\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(808944, 637)\n",
            "(808944, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVwC_DgmYWnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    }
  ]
}